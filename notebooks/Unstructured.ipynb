{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a4a9d9ed-cc98-4610-8471-4f6909258a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import io\n",
    "import uuid\n",
    "import base64\n",
    "import time \n",
    "from base64 import b64decode\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c301f09b-0153-498f-9daf-f8c8dee49b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in /usr/local/lib/python3.8/site-packages (0.2.4)\n",
      "Requirement already satisfied: langchain-core in /usr/local/lib/python3.8/site-packages (0.2.6)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.8/site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.8/site-packages (from langchain-community) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.8/site-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.8/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /usr/local/lib/python3.8/site-packages (from langchain-community) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.8/site-packages (from langchain-community) (0.1.77)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.8/site-packages (from langchain-community) (1.24.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.8/site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.8/site-packages (from langchain-community) (8.3.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.8/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.8/site-packages (from langchain-core) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.8/site-packages (from langchain-core) (2.7.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.8/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.8/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.8/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.8/site-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (0.2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.8/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.5)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.8/site-packages (from pydantic<3,>=1->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.8/site-packages (from pydantic<3,>=1->langchain-core) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.8/site-packages (from pydantic<3,>=1->langchain-core) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2->langchain-community) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2->langchain-community) (2024.6.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.8/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "452c20fa-0b38-489e-931f-1a80912319fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.messages import HumanMessage, SystemMessage\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.schema.document import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fe713a03-cdd0-4034-a1af-4fa7dff72281",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "30f64b8c-2705-4ac1-93d1-164094fc90c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_partition(path, file_name):\n",
    "  \"\"\"\n",
    "  Partition a PDF document into smaller chunks based on specified criteria.\n",
    "\n",
    "  Args:\n",
    "    path (str): The path to the directory where the PDF file is located.\n",
    "    file_name (str): The name of the PDF file.\n",
    "\n",
    "  Returns:\n",
    "    list: A list of raw PDF elements after partitioning.\n",
    "\n",
    "  \"\"\"\n",
    "  raw_pdf_elements = partition_pdf(\n",
    "    filename=path + file_name,\n",
    "    image_output_dir_path=path,\n",
    "    extract_images_in_pdf=True,\n",
    "    infer_table_structure=True,\n",
    "    chunking_strategy=\"by_title\",\n",
    "    max_characters=4000,\n",
    "    new_after_n_chars=3800,\n",
    "    combine_text_under_n_chars=2000,\n",
    "  )\n",
    "\n",
    "  return raw_pdf_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0e3abcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "poppler_path = os.path.abspath(os.getcwd()) + \"/content/\"\n",
    "path = os.path.abspath(os.getcwd()) + \"/content/\"\n",
    "file_name = \"medical_anatomy.pdf\"\n",
    "raw_pdf_elements = doc_partition(path,file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ac1b7119-20c0-4cbe-93d4-2e5cfe8fa038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_category(raw_pdf_elements):\n",
    "   \"\"\"\n",
    "   Categorizes the elements in the raw PDF.\n",
    "\n",
    "   Args:\n",
    "      raw_pdf_elements (list): A list of elements from the raw PDF.\n",
    "\n",
    "   Returns:\n",
    "      list: A list containing two sublists: texts and tables.\n",
    "         - texts: A list of text elements.\n",
    "         - tables: A list of table elements.\n",
    "   \"\"\"\n",
    "   tables = []\n",
    "   texts = []\n",
    "   for element in raw_pdf_elements:\n",
    "      if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "           tables.append(str(element))\n",
    "      elif \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
    "           texts.append(str(element))\n",
    "   return [texts, tables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e2adec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data_category(raw_pdf_elements)[0]\n",
    "tables = data_category(raw_pdf_elements)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bef5d0ba-9595-465f-b314-71ced13fc8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to take tables and text and then summarize tables only,\n",
    "def tables_summarize(data_category):\n",
    "    \"\"\"\n",
    "    Summarizes a list of tables or text chunks.\n",
    "\n",
    "    Args:\n",
    "        tables (list): A list of tables or text chunks to be summarized.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of concise summaries corresponding to each table or text chunk.\n",
    "\n",
    "    \"\"\"\n",
    "    prompt_text = \"\"\"You are an assistant tasked with summarizing tables and text. \\\n",
    "                    Give a concise summary of the table or text. Table or text chunk: {element} \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "    summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()\n",
    "    table_summaries = summarize_chain.batch(tables, {\"max_concurrency\": 5})\n",
    "    #text_summaries =  summarize_chain.batch(data_category[0], {\"max_concurrency\": 5})# no need to summarize\n",
    "\n",
    "    return table_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "35ea86fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_summaries = tables_summarize(data_category)\n",
    "text_summaries = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1a861881-bb1a-4853-b2f7-c0725c4a241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    ''' Encode an image file to base64 string '''\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    return encoded_string\n",
    "\n",
    "def image_captioning(img_base64, prompt):\n",
    "    '''\n",
    "    Generate image caption using OpenAI Chat model.\n",
    "\n",
    "    Parameters:\n",
    "    - img_base64 (str): The base64 encoded string representation of the image.\n",
    "    - prompt (str): The prompt or initial message for the chat model.\n",
    "\n",
    "    Returns:\n",
    "    - str: The generated image caption.\n",
    "\n",
    "    Example:\n",
    "    >>> img_base64 = \"iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAA...\"\n",
    "    >>> prompt = \"Describe the image.\"\n",
    "    >>> caption = image_captioning(img_base64, prompt)\n",
    "    >>> print(caption)\n",
    "    \"A beautiful sunset over the ocean.\"\n",
    "    '''\n",
    "    chat = ChatOpenAI(model=\"gpt-4-vision-preview\", max_tokens=1024)\n",
    "\n",
    "    message = [\n",
    "        HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img_base64}\"}},\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    response = chat.invoke(message)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fef7d13d-4726-410a-8beb-8b3057806b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Store base64 encoded images\n",
    "img_base64_list = []\n",
    "\n",
    "# Store image summaries\n",
    "image_summaries = []\n",
    "\n",
    "# Prompt\n",
    "prompt = \"Describe the image in detail. Be specific about graphs, such as bar plots.\"\n",
    "\n",
    "# Read images, encode to base64 strings\n",
    "for img_file in sorted(os.listdir(path)):\n",
    "    if img_file.endswith('.jpg'):\n",
    "        img_path = os.path.join(path, img_file)\n",
    "        base64_image = encode_image(img_path)\n",
    "        img_base64_list.append(base64_image)\n",
    "        #image_summaries.append(image_captioning(base64_image,prompt))\n",
    "        img_cap = image_captioning(base64_image,prompt)\n",
    "        time.sleep(10)\n",
    "        image_summaries.append(img_cap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6eee3228-4e68-4224-b817-06c836d69665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anatomy of the Somatosensory System\\n\\n1 FROM WIKIBOOKS\\n\\nOur somatosensory system consists of sensors in the skin and sensors in our muscles, tendons, and joints. The re- ceptors in the skin, the so called cutaneous receptors, tell us about temperature (thermoreceptors), pressure and sur- face texture (mechano receptors), and pain (nociceptors). The receptors in muscles and joints provide information about muscle length, muscle tension, and joint angles.\\n\\nThis is a sample document to showcase page-based formatting. It contains a chapter from aWikibook calledSensory Systems. None of the content has been changed in this article, but some content has been removed.\\n\\nCutaneous receptors\\n\\nSensory information from Meissner corpuscles and rapidly adapting afferents leads to adjustment of grip force when objects are lifted. These afferents respond with a brief burst of action potentials when objects move a small dis- tance during the early stages of lifting. In response to\\n\\nSebaceous  gland  Hairy skin  Free nerve ending  Merkel ’s receptor  Glabrous skin  Papillary Ridges  Septa  Meissne r’s corpuscle  Ruffini’s  corpuscle  Hair receptor  Pacinian corpuscle \\n\\nEpidermis\\n\\nDermis\\n\\nFigure 1: Receptors in the hu- man skin: Mechanoreceptors can be free receptors or encapsulated. Examples for free receptors are the hair receptors at the roots of hairs. Encapsulated receptors are the Pacinian corpuscles and the receptors in the glabrous (hair- less) skin: Meissner corpuscles, Ruffini corpuscles and Merkel’s disks.\\n\\n1 The following description is based on lecture notes from Laszlo Zaborszky, from Rutgers University.\\n\\n1\\n\\nFrom Wikibooks\\n\\nFigure 2: Mammalian muscle spindle showing typical position in a muscle (left), neuronal con- nections in spinal cord (middle) and expanded schematic (right). The spindle is a stretch receptor with its own motor supply con- sisting of several intrafusal mus- cle fibres. The sensory endings of a primary (group Ia) afferent and a secondary (group II) afferent coil around the non-contractile central portions of the intrafusal fibres.\\n\\n2\\n\\nextrafusal (main) muscle fascicles intrafusal muscle\\n\\nrapidly adapting afferent activity, muscle force increases reflexively until the gripped object no longer moves. Such a rapid response to a tactile stimulus is a clear indication of the role played by somatosensory neurons in motor ac- tivity.\\n\\nThe slowly adapting Merkel’s receptors are responsible for form and texture perception. As would be expected for receptors mediating form perception, Merkel’s receptors are present at high density in the digits and around the mouth (50/mm² of skin surface), at lower density in oth- er glabrous surfaces, and at very low density in hairy skin. This innervations density shrinks progressively with the passage of time so that by the age of 50, the density in hu- man digits is reduced to 10/mm². Unlike rapidly adapting axons, slowly adapting fibers respond not only to the ini- tial indentation of skin, but also to sustained indentation up to several seconds in duration.\\n\\nActivation of the rapidly adapting Pacinian corpuscles gives a feeling of vibration, while the slowly adapting Ruffini corpuscles respond to the lataral movement or stretching of skin.',\n",
       " 'Nociceptors\\n\\nNociceptors have free nerve endings. Functionally, skin nociceptors are either high-threshold mechanoreceptors\\n\\nAnatomy of the Somatosensory System',\n",
       " 'Table 1\\n\\nor polymodal receptors. Polymodal receptors respond not only to intense mechanical stimuli, but also to heat and to noxious chemicals. These receptors respond to minute punctures of the epithelium, with a response magnitude that depends on the degree of tissue deformation. They al- so respond to temperatures in the range of 40–60°C, and change their response rates as a linear function of warm- ing (in contrast with the saturating responses displayed by non-noxious thermoreceptors at high temperatures).\\n\\nPain signals can be separated into individual compo- nents, corresponding to different types of nerve fibers used for transmitting these signals. The rapidly transmit- ted signal, which often has high spatial resolution, is called first pain or cutaneous pricking pain. It is well local- ized and easily tolerated. The much slower, highly affec- tive component is called second pain or burning pain; it is poorly localized and poorly tolerated. The third or deep pain, arising from viscera, musculature and joints, is also poorly localized, can be chronic and is often associated with referred pain.\\n\\nNotice how figure captions and sidenotes are shown in the outside margin (on the left or right, depending on whether the page is left or right). Also, figures are floated to the top/ bottom of the page. Wide content, like the table and Figure 3, intrude into the outside margins.\\n\\nMuscle Spindles\\n\\nScattered throughout virtually every striated muscle in the body are long, thin, stretch receptors called muscle spin- dles. They are quite simple in principle, consisting of a few small muscle fibers with a capsule surrounding the middle third of the fibers. These fibers are called intrafusal fibers, in contrast to the ordinary extrafusal fibers. The ends of the intrafusal fibers are attached to extrafusal fibers, so when- ever the muscle is stretched, the intrafusal fibers are also\\n\\n3\\n\\nFrom Wikibooks\\n\\nForce control signal  Inter- neurons  Force (Golgi tendon organ) Force feedback  External forces  Driving signal  Muscle  Tendon organs  Muscle force  Load  Muscle length  Length control signal  Length & velocity feedback  Spindles  Gamma bias \\n\\nLength (secondary muscle-spindel afferents) Length error (primary muscle-spindel afferents) Velocity (primary muscle-spindel afferents)\\n\\nFigure 3: Feedback loops for proprioceptive signals for the perception and control of limb move- ments. Arrows indicate excitatory connections; filled circles inhibitory connections.\\n\\nstretched. The central region of each intrafusal fiber has few myofilaments and is non-contractile, but it does have one or more sensory endings applied to it. When the mus- cle is stretched, the central part of the intrafusal fiber is stretched and each sensory ending fires impulses.\\n\\nFor more examples of how to use HTML and CSS for paper-based publishing, seecss4.pub.\\n\\nMuscle spindles also receive a motor innervation. The large motor neurons that supply extrafusal muscle fibers are called alpha motor neurons, while the smaller ones sup- plying the contractile portions of intrafusal fibers are called gamma neurons. Gamma motor neurons can regu- late the sensitivity of the muscle spindle so that this sensi- tivity can be maintained at any given muscle length.',\n",
       " 'Joint receptors\\n\\nThe joint receptors are low-threshold mechanoreceptors and have been divided into four groups. They signal differ- ent characteristics of joint function (position, movements, direction and speed of movements). The free receptors or type 4 joint receptors are nociceptors.\\n\\n4']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a8b6dc15-69d7-4644-81fd-575796830de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The table describes different types of skin receptors and their functions. Hair receptors and Meissner’s corpuscles are rapidly adapting surface receptors with small receptive fields, used for detecting insects, fine vibrations, and recognizing texture. Pacinian corpuscles are deep receptors with large receptive fields, used for detecting diffuse vibrations like tapping with a pencil. Merkel’s receptors are slowly adapting and used for detecting spatial details like a round surface edge or brail. Ruffini’s corpuscles are used for detecting skin stretch and determining joint position in fingers.']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ae82ee55-3e18-44bf-8070-4bd854384a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The image is a detailed illustration of a cross-section of human skin, showing the differences between hairy skin and glabrous skin (which is hairless, like the skin on the palms of our hands or soles of our feet). The skin is depicted as a layered structure with various components labeled to show their position and relationship to each other.\\n\\nOn the left side, labeled as \"Hairy skin,\" there is a hair shaft protruding from the surface, with a hair receptor at the base, indicating a sensory function related to the hair. Below the hair receptor are other structures such as a sebaceous gland, which secretes oils for hair and skin lubrication, and a Pacinian corpuscle, which is a nerve receptor that detects pressure and vibration.\\n\\nTransitioning to the right, the skin changes to \"Glabrous skin,\" where there are no hairs. Instead, the surface shows papillary ridges which are typical of the fingerprint patterns found on fingertips. Within the glabrous skin, we can see a Meissner\\'s corpuscle, which is sensitive to light touch.\\n\\nBetween the different types of skin, the diagram shows various other sensory receptors and structures including:\\n\\n- Free nerve ending: Likely involved in pain and temperature sensation.\\n- Merkel\\'s receptor: A nerve ending associated with sensing steady pressure and texture.\\n- Ruffini\\'s corpuscle: A mechanoreceptor sensitive to skin stretch and sustained pressure.\\n\\nThe skin layers are indicated by different shades of pink, with the outermost layer appearing lighter and the inner layers progressively darker. Beneath the skin, the illustration suggests the presence of deeper tissue, but this is not detailed and remains unlabelled.\\n\\nThe image is informative and educational, likely used for teaching purposes in biology, anatomy, or medicine to explain the sensory functions of the skin and the different types of receptors involved in the sense of touch.',\n",
       " 'This image is an illustration depicting the neuromuscular components involved in muscle contraction and sensation. On the left, there is a drawing of a human leg with the upper leg muscle (quadriceps) highlighted in red. A magnified view of a muscle spindle is shown to the right of the leg, which is a sensory receptor within the muscle.\\n\\nThe muscle spindle is enlarged to show its internal structure and connections. It is represented as a cylindrical structure with multiple parts:\\n\\n1. Gamma (γ) efferent (motor) neurons and alpha (α) efferent (motor) neurons are shown innervating the muscle spindle. The γ-motor neurons are depicted at the bottom, and the α-motor neurons are shown at the top, with arrows indicating their connection to the muscle spindle.\\n2. There are two types of afferent (sensory) nerve fibers labeled: Type Ia afferent fibers, which are thick and have a direct connection to the central part of the muscle spindle, and Type II afferent fibers, which are thinner and connect to the ends of the spindle.\\n3. The central portion of the muscle spindle is labeled as \"intrafusal muscle fibers,\" which are the specialized fibers within the spindle.\\n4. The surrounding muscle tissue, labeled as \"extrafusal (main) muscle fascicles,\" represents the main contractile part of the muscle outside the spindle.\\n\\nOverall, the diagram is meant to show the relationship between muscle spindles, sensory neurons, and motor neurons in the process of muscle control and proprioception (the body\\'s ability to sense movement, action, and location).',\n",
       " 'The image is a schematic diagram illustrating the neuromuscular control system, which is part of how the human body regulates muscle tension and movement. This block diagram represents a feedback loop system with various components interacting with each other.\\n\\nAt the top left, there is a \"Force control signal\" leading into a block labeled \"Inter-neurons.\" Below this is another signal labeled \"Driving signal\" pointing towards a circle with the Greek letter \"alpha (α)\" inside, which represents alpha motor neurons. These neurons send signals to the \"Muscle\" block, which then connects to \"Tendon organs.\" The tendon organs provide \"Force feedback,\" which is indicated by the text \"Force (Golgi tendon organ)\" next to an arrow looping back to the inter-neurons.\\n\\nTo the right of the \"Muscle\" block, there is an arrow labeled \"Muscle force\" pointing towards a block labeled \"Load.\" Above this arrow, \"External forces\" are shown to influence the muscle force. An arrow pointing to the right labeled \"Muscle length\" comes out of the \"Load\" block, completing a loop back to the \"Muscle\" block.\\n\\nAt the bottom of the diagram, there\\'s a \"Length control signal\" that leads into a circle labeled with the Greek letter \"gamma (γ),\" representing gamma motor neurons. These neurons influence \"Spindles,\" which in turn, provide \"Length & velocity feedback\" to the alpha motor neuron circle. The spindles receive \"Gamma bias\" from the gamma motor neurons, and there\\'s also a note pointing to the line between the spindles and the alpha motor neurons labeled \"spindle afferents\" (with \"spindle afferents\" being repeated and crossed out) indicating some form of correction or emphasis on this pathway.\\n\\nThe relationships between the blocks and circles are represented by straight lines with arrowheads, indicating the direction of signal flow. Overall, the diagram depicts how muscle tension and length are regulated through feedback mechanisms involving alpha and gamma motor neurons, muscle spindles, and Golgi tendon organs.']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "06d01706-8754-4c36-8d1e-c4a0246cec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_image_text_types(docs):\n",
    "    ''' \n",
    "    Split base64-encoded images and texts.\n",
    "    \n",
    "    Args:\n",
    "        docs (list): A list of documents containing base64-encoded images and texts.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary containing two lists - \"images\" and \"texts\". The \"images\" list contains the base64-encoded images, and the \"texts\" list contains the texts.\n",
    "    '''\n",
    "    images = []\n",
    "    texts = []\n",
    "    for doc in docs:\n",
    "        try:\n",
    "            b64decode(doc)\n",
    "            images.append(doc)\n",
    "        except binascii.Error:\n",
    "            texts.append(doc)\n",
    "    return {\n",
    "        \"images\": images,\n",
    "        \"texts\": texts\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "05b9d975-5a30-4515-8681-fea17d87d746",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma(collection_name=\"multi_modal_rag\",\n",
    "                     embedding_function=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "24c53597-cac8-49ef-8243-97be34c10474",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = InMemoryStore()\n",
    "id_key = \"doc_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b0812fca-0d5a-48e1-b3fc-ff43d9359004",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    id_key=id_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "115d0b27-17e7-41a8-9c7c-0eea91de731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ids = [str(uuid.uuid4()) for _ in texts]\n",
    "summary_texts = [\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(text_summaries)\n",
    "]\n",
    "retriever.vectorstore.add_documents(summary_texts)\n",
    "retriever.docstore.mset(list(zip(doc_ids, texts)))\n",
    "\n",
    "# Add tables\n",
    "table_ids = [str(uuid.uuid4()) for _ in tables]\n",
    "summary_tables = [\n",
    "    Document(page_content=s, metadata={id_key: table_ids[i]})\n",
    "    for i, s in enumerate(table_summaries)\n",
    "]\n",
    "retriever.vectorstore.add_documents(summary_tables)\n",
    "retriever.docstore.mset(list(zip(table_ids, tables)))\n",
    "\n",
    "# Add image summaries\n",
    "img_ids = [str(uuid.uuid4()) for _ in img_base64_list]\n",
    "summary_img = [\n",
    "    Document(page_content=s, metadata={id_key: img_ids[i]})\n",
    "    for i, s in enumerate(image_summaries)\n",
    "]\n",
    "retriever.vectorstore.add_documents(summary_img)\n",
    "retriever.docstore.mset(list(zip(img_ids, img_base64_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "157c2a00-7769-482d-a784-367c3f15e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "def prompt_func(dict):\n",
    "    format_texts = \"\\n\".join(dict[\"context\"][\"texts\"])\n",
    "    return [\n",
    "        HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\": f\"\"\"Answer the question based only on the following context, which can include text, tables, and the below image:\n",
    "Question: {dict[\"question\"]}\n",
    "\n",
    "Text and tables:\n",
    "{format_texts}\n",
    "\"\"\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{dict['context']['images'][0]}\"}},\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-4-vision-preview\", max_tokens=1024)\n",
    "\n",
    "# RAG pipeline\n",
    "chain = (\n",
    "    {\"context\": retriever | RunnableLambda(split_image_text_types), \"question\": RunnablePassthrough()}\n",
    "    | RunnableLambda(prompt_func)\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "725e91bd-2cc8-447f-918f-9051a89469a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The image depicts a schematic representation of the neuromuscular feedback loops involved in muscle control. Feedback loops are systems in which outputs of a process are used as inputs to control the behavior of the process itself, often leading to regulation of the function.\\n\\nIn the context of the image, there are two primary feedback mechanisms illustrated:\\n\\n1. Muscle Spindle Feedback Loop:\\n   - Muscle spindles are sensory receptors within the muscle that detect changes in muscle length and the rate of change in length (velocity).\\n   - When a muscle stretches, the spindles are also stretched and send information (length and velocity feedback) to the central nervous system (CNS) via afferent nerve fibers.\\n   - The CNS processes this information and sends a response back to the muscle via α motor neurons (driving signal) to adjust the contraction and control muscle length.\\n   - Additionally, γ motor neurons (gamma bias) adjust the sensitivity of the muscle spindles.\\n\\n2. Golgi Tendon Organ Feedback Loop:\\n   - Golgi tendon organs are located at the junctions between muscles and tendons and detect tension changes in the muscle, providing force feedback.\\n   - When the muscle contracts and generates force, this information is conveyed to the CNS.\\n   - The CNS can then modulate the muscle activity through interneurons that can inhibit or facilitate the α motor neurons, thus regulating the force generated by the muscle.\\n\\nThese feedback loops are crucial for maintaining posture, coordinating movements, and preventing muscle damage by adjusting muscle activity in response to internal and external forces. The interplay between these loops allows the body to perform precise and smooth movements.'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    \"Explain about the feedback loops\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa4ca37-4e2b-4c00-901b-1adb094c8626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e692a-cc4f-4cbb-b610-ab26967337dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
